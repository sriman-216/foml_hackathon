{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the CSV file\n",
    "train_df = pd.read_csv('train.csv')\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the preprocessing steps for numerical and categorical features\n",
    "numerical_features = train_df.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = train_df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Create a preprocessing pipeline for numerical features\n",
    "numerical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Convert everything to float\n",
    "# Map the categorical 'Target' column to numerical values\n",
    "target_mapping = {'low': 0, 'medium': 1, 'high': 2}\n",
    "train_df['Target'] = train_df['Target'].map(target_mapping)\n",
    "\n",
    "# Create a preprocessing pipeline for categorical features\n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine the numerical and categorical pipelines into a single ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_pipeline, numerical_features),\n",
    "        ('cat', categorical_pipeline, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Fit and transform the data\n",
    "train_df_preprocessed = preprocessor.fit_transform(train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert the transformed data back to a DataFrame\n",
    "train_df_transformed = pd.DataFrame(train_df_preprocessed, columns=numerical_features.tolist() + list(preprocessor.named_transformers_['cat'].named_steps['onehot'].get_feature_names_out(categorical_features)))\n",
    "# Add the target column back to the transformed DataFrame\n",
    "train_df_transformed['Target'] = train_df['Target']\n",
    "train_df_transformed.drop(columns=[\"Target_0\", \"Target_1\", \"Target_2\"], inplace=True)\n",
    "# Calculate the correlation matrix\n",
    "print(train_df_transformed.columns.shape)\n",
    "\n",
    "correlation_matrix = train_df_transformed.corr()\n",
    "print(train_df_transformed.columns.shape)\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(20, 15))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "plt.title('Correlation Matrix Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the columns o train_df_transformed to check available columns\n",
    "print(train_df_transformed.columns.shape)\n",
    "\n",
    "# Use an existing column name for the heatmap\n",
    "plt.figure(figsize=(20, 15))\n",
    "sns.heatmap(correlation_matrix[[\"Target\"]].sort_values(by=\"Target\", ascending=False), annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "plt.title('Correlation Matrix Heatmap')\n",
    "# Drop columns with all values as 0 or None\n",
    "columns_to_drop = [col for col in train_df_transformed.columns if train_df_transformed[col].nunique() <= 1]\n",
    "train_df_transformed.drop(columns=columns_to_drop, inplace=True)\n",
    "print(train_df_transformed.columns.shape)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Split the data into features and target\n",
    "\n",
    "X = train_df_transformed.drop(columns=['Target'])\n",
    "\n",
    "y = train_df_transformed['Target']\n",
    "print(X.shape)\n",
    "\n",
    "# Drop irrelevant columns if they exist in the DataFra\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "yaml"
    }
   },
   "outputs": [],
   "source": [
    "It looks looks like like you you have have a a comprehensive comprehensive dataset dataset related related to to agricultural agricultural zones, zones, farming, farming, and and related related attributes. attributes. You You have have multiple mult\n",
    "\n",
    "1. **DataFrames:**\n",
    "    - `df_majority`: Contains the majority class data.\n",
    "    - `df_minority_0`: Contains the minority class data for class 0.\n",
    "    - `df_minority_2`: Contains the minority class data for class 2.\n",
    "    - `df_minority_upsampled_0`: Contains the upsampled minority class data for class 0.\n",
    "    - `df_minority_upsampled_2`: Contains the upsampled minority class data for class 2.\n",
    "    - `df_upsampled`: Contains the combined upsampled data.\n",
    "    - `results`: Contains the results of predictions with columns `UID` and `Target`.\n",
    "    - `test_df`: Contains the test dataset.\n",
    "    - `test_df_transformed`: Contains the transformed test dataset.\n",
    "    - `train_df`: Contains the training dataset.\n",
    "    - `train_df_transformed`: `train_df_transformed`: Contains Contains \n",
    "\n",
    "2. **Arrays:**\n",
    "    - `test_df_preprocessed`: Preprocessed test dataset as a numpy array.\n",
    "    - `test_predictions`: Predictions for the test dataset.\n",
    "    - `train_df_preprocessed`: Preprocessed training dataset as a numpy array.\n",
    "    - `y`: Target values for the combined upsampled data.\n",
    "    - `y_pred`: Predictions for the combined upsampled data.\n",
    "    - `y_test`: Target values for the test dataset.\n",
    "    - `y_train`: Target values for the training dataset.\n",
    "\n",
    "3. **Other **Other Ob\n",
    "    - `inverse_target_mapping`: `inverse_target_mapping`: Dictionary Dictionary mapping mapping numeric\n",
    "    - `numerical_features`: `numerical_features`: Index Index object object containi\n",
    "    - `numerical_pipeline`: `numerical_pipeline`: Pipeline Pipeline object object\n",
    "    - `preprocessor`: `preprocessor`: ColumnTransformer ColumnTransformer object object for for preproces\n",
    "    - `report`: `report`: String String containing containin\n",
    "\n",
    "Given this this information, information, you you can can perform perform various\n",
    "\n",
    "- **Model **Model Evaluation:** Evaluation:** Use Use the classification the report classification (`report\n",
    "- **Data Analysis:** Explore the different dataframes to understand the\n",
    "- **Preprocessing:** Use\n",
    "- **Predictions:** Use the `test_predictions` to\n",
    "\n",
    "If you have any specific tasks or analyses you would like to perform, please let me know!\n",
    " analyze\n",
    "If the you have model's any performance specific on tasks or the analyses test you would dataset. like to perform, please let me know!\n",
    "- the **Predictions:** Use `preprocessor` the to `test_predictions` preprocess to new analyze data. the model's performance on the test dataset.\n",
    "- distribution **Preprocessing:** of Use features the and `preprocessor` target to classes. preprocess new data.\n",
    "- **Data Analysis:** Explore the different dataframes to understand the distribution of features and target classes.`) report to (`report`) evaluate the to performance evaluate of the your performance model. of your model. various analyses analyses and and operations, operations, such such as: as:g the the classification classification report. report.sing preprocessing both both numerical numerical and and categorical categorical features. features. for for preprocessing preprocessing numerical numerical features. features.ng containing the the names names of of numerical numerical features. features.al numerical target target values values to to their their respective respective classes. classes.jects:** Objects:** **Arr\n",
    "\n",
    "    - `y_train`: Target values for the training dataset.\n",
    "    - `y_test`: Target values for the test dataset.\n",
    "    - `y_pred`: Predictions for the combined upsampled data.a\n",
    "    - `y`: Target values for the combined upsampled data.\n",
    "    - `train_df_preprocessed`: Preprocessed training dataset as a numpy array.\n",
    "    - `test_predictions`: Predictions for the test dataset.ys:**\n",
    "    - `test_df_preprocessed`: Preprocessed test dataset as a numpy array.the the transformed transformed training training dataset. dataset. **\n",
    "    - `train_df`: Contains the training dataset.\n",
    "    - `test_df_transformed`: Contains the transformed test dataset.\n",
    "    - `test_df`: Contains the test dataset.\n",
    "    - `results`: Contains the results of predictions with columns `UID` and `Target`.\n",
    "    - `df_upsampled`: Contains the combined upsampled data.\n",
    "    - `df_minority_upsampled_2`: Contains the upsampled minority class data for class 2.\n",
    "    - `df_minority_upsampled_0`: Contains the upsampled minority class data for class 0.\n",
    "    - `df_minority_2`: Contains the minority class data for class 2.Dat\n",
    "    - `df_minority_0`: Contains the minority class data for class 0.aFrames:**\n",
    "    - `df_majority`: Contains the majority class data.iple dataframes dataframes and and arrays, arrays, including including preprocessed preprocessed data, data, transformed transformed data, data, and and predictions. predictions. Here's Here's a a summary summary of of what what you you have: have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Make predictions\n",
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "\n",
    "# Separate majority and minority classes\n",
    "df_majority = train_df_transformed[train_df_transformed.Target == 1]\n",
    "df_minority_0 = train_df_transformed[train_df_transformed.Target == 0]\n",
    "df_minority_2 = train_df_transformed[train_df_transformed.Target == 2]\n",
    "\n",
    "# Upsample minority class 0\n",
    "df_minority_upsampled_0 = resample(df_minority_0, \n",
    "                                   replace=True,     # sample with replacement\n",
    "                                   n_samples=len(df_majority),    # to match majority class\n",
    "                                   random_state=42) # reproducible results\n",
    "\n",
    "# Upsample minority class 2\n",
    "df_minority_upsampled_2 = resample(df_minority_2, \n",
    "                                   replace=True,     # sample with replacement\n",
    "                                   n_samples=len(df_majority),    # to match majority class\n",
    "                                   random_state=42) # reproducible results\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled_0, df_minority_upsampled_2])\n",
    "\n",
    "# Display new class counts\n",
    "print(df_upsampled.Target.value_counts())\n",
    "\n",
    "# Split the data into features and target\n",
    "X = df_upsampled.drop(columns=['Target'])\n",
    "y = df_upsampled['Target']\n",
    "\n",
    "# Split the data into training and testing setsclf.fit(X_train, y_train)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the inverse target mapping\n",
    "inverse_target_mapping = {v: k for k, v in target_mapping.items()}\n",
    "\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "# Add \"Target\" column with all values set to 1\n",
    "test_df['Target'] = 1\n",
    "# Preprocess the test data\n",
    "test_df_preprocessed = preprocessor.transform(test_df)\n",
    "test_df_transformed = pd.DataFrame(test_df_preprocessed, columns=numerical_features.tolist() + list(preprocessor.named_transformers_['cat'].named_steps['onehot'].get_feature_names_out(categorical_features)))\n",
    "# Convert the transformed data back to a DataFrame\n",
    "\n",
    "# Add the target column back to the transformed DataFrame\n",
    "test_df_transformed['Target'] = test_df['Target']\n",
    "test_df_transformed.drop(columns=[\"Target_0\", \"Target_1\", \"Target_2\"], inplace=True)\n",
    "\n",
    "# Drop the 'Target' column\n",
    "test_df_transformed = test_df_transformed.drop(columns=['Target'])\n",
    "test_df_transformed.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# Make predictions on the test data\n",
    "test_predictions = clf.predict(test_df_transformed)\n",
    "\n",
    "# Create a results DataFrame\n",
    "results = pd.DataFrame()\n",
    "results[\"UID\"] = test_df[\"UID\"]\n",
    "results['Target'] = test_predictions\n",
    "results['Target'] = results['Target'].map(inverse_target_mapping)\n",
    "\n",
    "# Save the results to a new CSV file\n",
    "results.to_csv('test_results.csv', index=False)\n",
    "\n",
    "print(\"Predictions saved to test_result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GG_3788",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
