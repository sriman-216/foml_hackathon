{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the CSV file\n",
    "train_df = pd.read_csv('train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of null values in each column\n",
    "null_percentage = train_df.isnull().mean() * 100\n",
    "\n",
    "# Sort the columns by the percentage of null values in descending order\n",
    "sorted_null_percentage = null_percentage.sort_values(ascending=False)\n",
    "\n",
    "# Print the sorted percentage of null values\n",
    "for column in sorted_null_percentage.index:\n",
    "    print(f\"{column}: {sorted_null_percentage[column]:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "columns_with_high_nulls = [\n",
    "    'FarmClassification', 'PerimeterGuardPlantsArea', 'UndergroundStorageSqft', \n",
    "    'FieldZoneLevel', 'HarvestStorageSqft', 'HasGreenHouse', \n",
    "    'CropFieldConfiguration', 'FieldConstructionType', 'CultivatedAndWildArea', \n",
    "    'FieldShadeCover', 'ReservoirType', 'TotalReservoirSize', \n",
    "    'ReservoirWithFilter', 'HasPestControl', 'TaxOverdueYear', \n",
    "    'TaxOverdueStatus', 'FarmShedAreaSqft', 'TotalAreaSqft', \n",
    "    'PrimaryCropAreaSqft2', 'PrimaryCropAreaSqft', 'NumberGreenHouses', \n",
    "    'PartialIrrigationSystemCount', 'NaturalLakePresence'\n",
    "]\n",
    "print(len(columns_with_high_nulls))\n",
    "print(len(train_df.columns))\n",
    "\n",
    "# Drop columns with high percentage of null values\n",
    "train_df = train_df.drop(columns=columns_with_high_nulls)\n",
    "print(train_df.columns)\n",
    "print(len(train_df.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  plt.show()\n",
    "print(f\"Total number of rows: {len(train_df)}\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the threshold for missing values\n",
    "print(train_df.columns)\n",
    "median_fill_cols=['AgriculturalPostalZone','AgricultureZoningCode','CropSpeciesVariety',\n",
    "        'FarmVehicleCount','DistrictId','FarmingCommunityId','FarmingUnitCount',\n",
    "        'FieldEstablishedYear','HarvestProcessingType','LandUsageType', 'SoilFertilityType', 'StorageAndFacilityCount', \n",
    "        'NumberOfFarmingZones','OtherZoningCode','RawLocationId','NationalRegionCode',\n",
    "        'TownId','TypeOfIrrigationSystem','ValuationYear', 'MainIrrigationSystemCount',\n",
    "        'WaterAccessPoints', 'WaterAccessPointsCalc', 'WaterReservoirCount'\n",
    "       ]\n",
    "mean_fill_cols= [\n",
    "    'CultivatedAreaSqft1', 'FarmEquipmentArea', \n",
    "    'FieldSizeSqft', 'Latitude', 'Longitude',  \n",
    "    'TaxAgrarianValue', 'TaxLandValue', 'TotalCultivatedAreaSqft', \n",
    "    'TotalTaxAssessed', 'TotalValue'\n",
    "]\n",
    "\n",
    "# Identify the dropped columns\n",
    "# Display the dropped columns\n",
    "target_mapping = {'low': 0, 'medium': 1, 'high': 2}\n",
    "train_df[\"Target\"] = train_df['Target'].map(target_mapping)\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dropped_columns = ['ReservoirType', 'HasPestControl', 'TotalReservoirSize', 'WaterReservoirCount', \n",
    "                   'FarmingCommunityId', 'PrimaryCropAreaSqft', 'FieldConstructionType', \n",
    "                   'HarvestStorageSqft', 'NumberGreenHouses', 'PartialIrrigationSystemCount', \n",
    "                   'FarmShedAreaSqft', 'PrimaryCropAreaSqft2', 'UndergroundStorageSqft', \n",
    "                   'HarvestProcessingType', 'ReservoirWithFilter', 'FarmingUnitCount', \n",
    "                   'FarmEquipmentArea', 'SoilFertilityType', 'PerimeterGuardPlantsArea', \n",
    "                   'TaxOverdueYear', 'CultivatedAndWildArea', 'NaturalLakePresence', \n",
    "                   'FarmVehicleCount', 'FarmClassification', 'TaxOverdueStatus', 'FieldShadeCover', \n",
    "                   'FieldZoneLevel', 'OtherZoningCode', 'NumberOfFarmingZones', 'CropFieldConfiguration', \n",
    "                   'TypeOfIrrigationSystem', 'HasGreenHouse', 'TotalAreaSqft']\n",
    "\n",
    "mean_fill_cols = ['AgricultureZoningCode', 'CropSpeciesVariety', 'CultivatedAreaSqft1', \n",
    "                  'DistrictId', 'FieldEstablishedYear', 'LandUsageType', 'Latitude', 'Longitude', \n",
    "                  'MainIrrigationSystemCount', 'NationalRegionCode', 'RawLocationId', \n",
    "                  'StorageAndFacilityCount', 'TaxAgrarianValue', 'TaxLandValue', 'TotalCultivatedAreaSqft', \n",
    "                  'TotalTaxAssessed', 'TotalValue', 'ValuationYear', 'WaterAccessPoints', \n",
    "                  'WaterAccessPointsCalc']\n",
    "\n",
    "median_fill_cols = ['FieldSizeSqft', 'TownId']\n",
    "\n",
    "# Fill missing values with mean for symmetrically distributed data\n",
    "train_df[mean_fill_cols] = train_df[mean_fill_cols].fillna(train_df[mean_fill_cols].mean())\n",
    "\n",
    "# Fill missing values with median for skewed data\n",
    "train_df[median_fill_cols] = train_df[median_fill_cols].fillna(train_df[median_fill_cols].median())\n",
    "\n",
    "correlation_matrix = train_df.corr()\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(20, 15))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "plt.title('Correlation Matrix Heatmap')\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort correlation values with respect to the target variable\n",
    "sorted_correlation = correlation_matrix[\"Target\"].sort_values().to_frame()\n",
    "\n",
    "# Identify highly correlated column pairs\n",
    "highest_correlatedcolumes = [[col1, col2, correlation_matrix.loc[col1, col2]] \n",
    "                             for col1 in sorted_correlation.index \n",
    "                             for col2 in sorted_correlation.index \n",
    "                             if col1 != col2 and (correlation_matrix.loc[col1, col2] > 0.95 or correlation_matrix.loc[col1, col2] < -0.7)]\n",
    "\n",
    "seen_pairs = set()\n",
    "for col1, col2, corr in highest_correlatedcolumes:\n",
    "    if (col2, col1) not in seen_pairs:\n",
    "        print(f\"{col1} and {col2} --->{corr:.2f}\")\n",
    "        seen_pairs.add((col1, col2))\n",
    "\n",
    "# Drop irrelevant and constant columns\n",
    "unrelaved_features = [\"UID\", \"NationalRegionCode\"]\n",
    "columns_to_drop = [col for col in train_df.columns if train_df[col].nunique() <= 1]\n",
    "train_df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "print(train_df.columns.shape)\n",
    "print(columns_to_drop)\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "columns_to_drop=['UID', 'NationalRegionCode', 'TaxLandValue', 'WaterAccessPointsCalc','RawLocationId','WaterAccessPoints','CultivatedAreaSqft1']\n",
    "\n",
    "# Split the data into features and target\n",
    "train_df.drop(columns=columns_to_drop, inplace=True)\n",
    "X = train_df.drop(columns=['Target'])\n",
    "\n",
    "\n",
    "y = train_df['Target']\n",
    "print(X.shape)\n",
    "\n",
    "# Drop irrelevant columns if they exist in the DataFra\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Define the number of estimators\n",
    "n_es = 200\n",
    "\n",
    "# Set up classifier with best parameters\n",
    "best_params = {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200, 'objective': 'multi:softmax', 'random_state': 42, 'subsample': 0.8}\n",
    "clf = XGBClassifier(**best_params)\n",
    "\n",
    "# Separate majority and minority classes\n",
    "df_majority = train_df[train_df.Target == 1]\n",
    "df_minority_0 = train_df[train_df.Target == 0]\n",
    "df_minority_2 = train_df[train_df.Target == 2]\n",
    "\n",
    "# Upsample minority class 0\n",
    "df_minority_upsampled_0 = resample(df_minority_0, \n",
    "                                   replace=True,     \n",
    "                                   n_samples=len(df_majority),    \n",
    "                                   random_state=42)\n",
    "\n",
    "# Upsample minority class 2\n",
    "df_minority_upsampled_2 = resample(df_minority_2, \n",
    "                                   replace=True,     \n",
    "                                   n_samples=len(df_majority),    \n",
    "                                   random_state=42)\n",
    "\n",
    "# Combine majority class with upsampled minority classes\n",
    "df_upsampled = pd.concat([df_minority_upsampled_0, df_majority, df_minority_upsampled_2])\n",
    "\n",
    "# Display new class counts\n",
    "print(df_upsampled.Target.value_counts())\n",
    "\n",
    "# Split the data into features and target\n",
    "X = df_upsampled.drop(columns=['Target'])\n",
    "y = df_upsampled['Target']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the classifier and make predictions\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "def make_predictions(test_fname, predictions_fname):\n",
    "#TODO: complete this function to save predictions to the csv file predictions_fname\n",
    "#this is an example, you need to modify the code below to fit your workflow\n",
    "#### start code ####\n",
    "    test_df = pd.read_csv(test_fname)\n",
    "    columns_with_high_nulls = [\n",
    "    'FarmClassification', 'PerimeterGuardPlantsArea', 'UndergroundStorageSqft', \n",
    "    'FieldZoneLevel', 'HarvestStorageSqft', 'HasGreenHouse', \n",
    "    'CropFieldConfiguration', 'FieldConstructionType', 'CultivatedAndWildArea', \n",
    "    'FieldShadeCover', 'ReservoirType', 'TotalReservoirSize', \n",
    "    'ReservoirWithFilter', 'HasPestControl', 'TaxOverdueYear', \n",
    "    'TaxOverdueStatus', 'FarmShedAreaSqft', 'TotalAreaSqft', \n",
    "    'PrimaryCropAreaSqft2', 'PrimaryCropAreaSqft', 'NumberGreenHouses', \n",
    "    'PartialIrrigationSystemCount', 'NaturalLakePresence'\n",
    "    ]\n",
    "    columns_to_drop=['UID','WaterReservoirCount', 'NationalRegionCode', 'TaxLandValue', 'WaterAccessPointsCalc','RawLocationId','WaterAccessPoints','CultivatedAreaSqft1']\n",
    "    test_df.drop(columns=columns_with_high_nulls, inplace=True)\n",
    "    mean_fill_cols = ['AgricultureZoningCode', 'CropSpeciesVariety', 'CultivatedAreaSqft1', 'DistrictId', 'FieldEstablishedYear', 'LandUsageType', 'Latitude', 'Longitude', 'MainIrrigationSystemCount', 'NationalRegionCode', 'RawLocationId', 'StorageAndFacilityCount', 'TaxAgrarianValue', 'TaxLandValue', 'TotalCultivatedAreaSqft', 'TotalTaxAssessed', 'TotalValue', 'ValuationYear', 'WaterAccessPoints', 'WaterAccessPointsCalc']\n",
    "    median_fill_cols = ['FieldSizeSqft', 'TownId']\n",
    "\n",
    "    test_df[mean_fill_cols] = test_df[mean_fill_cols].fillna(test_df[mean_fill_cols].mean())\n",
    "\n",
    "# Fill missing values with median for skewed data\n",
    "    test_df[median_fill_cols] = test_df[median_fill_cols].fillna(test_df[median_fill_cols].mean())\n",
    "\n",
    "    test_uid = test_df[[\"UID\"]].copy()\n",
    "\n",
    "    test_df.drop(columns=columns_to_drop, inplace=True)\n",
    "    preds = clf.predict(test_df)\n",
    "    inverse_target_mapping = {0:'low',1:'medium',2:'high'}\n",
    "    preds = pd.Series(preds).map(inverse_target_mapping)\n",
    "    # preds=preds.flatten()\n",
    "    # preds = preds.map(target_mapping)\n",
    "    test_uid[\"Target\"] = preds\n",
    "    test_uid.to_csv(predictions_fname, index=False)\n",
    "#### end code ####\n",
    "import argparse\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--train-file\", type=str, help=\"Path to train.csv\")\n",
    "    parser.add_argument(\"--test-file\", type=str, help=\"Path to test.csv\")\n",
    "    parser.add_argument(\"--predictions-file\", type=str, help=\"Save path for predictions\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    make_predictions(args.test_file, args.predictions_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
